{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mCudaSupportError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[1;32mIn [1]\u001B[0m, in \u001B[0;36m<cell line: 44>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     41\u001B[0m blockspergrid \u001B[38;5;241m=\u001B[39m (\u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m8\u001B[39m, \u001B[38;5;241m8\u001B[39m)  \u001B[38;5;66;03m# Blocks per grid\u001B[39;00m\n\u001B[0;32m     42\u001B[0m A\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;241m3\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m \u001B[43manother_kernel\u001B[49m\u001B[43m[\u001B[49m\u001B[43mblockspergrid\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mthreadsperblock\u001B[49m\u001B[43m]\u001B[49m(A)\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:862\u001B[0m, in \u001B[0;36mDispatcher.__getitem__\u001B[1;34m(self, args)\u001B[0m\n\u001B[0;32m    860\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(args) \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m [\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m4\u001B[39m]:\n\u001B[0;32m    861\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmust specify at least the griddim and blockdim\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m--> 862\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconfigure\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:857\u001B[0m, in \u001B[0;36mDispatcher.configure\u001B[1;34m(self, griddim, blockdim, stream, sharedmem)\u001B[0m\n\u001B[0;32m    855\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mconfigure\u001B[39m(\u001B[38;5;28mself\u001B[39m, griddim, blockdim, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, sharedmem\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m):\n\u001B[0;32m    856\u001B[0m     griddim, blockdim \u001B[38;5;241m=\u001B[39m normalize_kernel_dimensions(griddim, blockdim)\n\u001B[1;32m--> 857\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_KernelConfiguration\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgriddim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mblockdim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstream\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msharedmem\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:718\u001B[0m, in \u001B[0;36m_KernelConfiguration.__init__\u001B[1;34m(self, dispatcher, griddim, blockdim, stream, sharedmem)\u001B[0m\n\u001B[0;32m    715\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msharedmem \u001B[38;5;241m=\u001B[39m sharedmem\n\u001B[0;32m    717\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m config\u001B[38;5;241m.\u001B[39mCUDA_LOW_OCCUPANCY_WARNINGS:\n\u001B[1;32m--> 718\u001B[0m     ctx \u001B[38;5;241m=\u001B[39m \u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    719\u001B[0m     smcount \u001B[38;5;241m=\u001B[39m ctx\u001B[38;5;241m.\u001B[39mdevice\u001B[38;5;241m.\u001B[39mMULTIPROCESSOR_COUNT\n\u001B[0;32m    720\u001B[0m     grid_size \u001B[38;5;241m=\u001B[39m griddim[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;241m*\u001B[39m griddim[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m*\u001B[39m griddim[\u001B[38;5;241m2\u001B[39m]\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:220\u001B[0m, in \u001B[0;36mget_context\u001B[1;34m(devnum)\u001B[0m\n\u001B[0;32m    216\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_context\u001B[39m(devnum\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    217\u001B[0m     \u001B[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m    return the CUDA context.\u001B[39;00m\n\u001B[0;32m    219\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 220\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_runtime\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_or_create_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevnum\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:138\u001B[0m, in \u001B[0;36m_Runtime.get_or_create_context\u001B[1;34m(self, devnum)\u001B[0m\n\u001B[0;32m    136\u001B[0m attached_ctx \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_attached_context()\n\u001B[0;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m attached_ctx \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_or_create_context_uncached\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevnum\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    140\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m attached_ctx\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:153\u001B[0m, in \u001B[0;36m_Runtime._get_or_create_context_uncached\u001B[1;34m(self, devnum)\u001B[0m\n\u001B[0;32m    147\u001B[0m \u001B[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001B[39;00m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;124;03mThis version does not read the cache.\u001B[39;00m\n\u001B[0;32m    149\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    150\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;66;03m# Try to get the active context in the CUDA stack or\u001B[39;00m\n\u001B[0;32m    152\u001B[0m     \u001B[38;5;66;03m# activate GPU-0 with the primary context\u001B[39;00m\n\u001B[1;32m--> 153\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m driver\u001B[38;5;241m.\u001B[39mget_active_context() \u001B[38;5;28;01mas\u001B[39;00m ac:\n\u001B[0;32m    154\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m ac:\n\u001B[0;32m    155\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_activate_context_for(\u001B[38;5;241m0\u001B[39m)\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:487\u001B[0m, in \u001B[0;36m_ActiveContext.__enter__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    485\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    486\u001B[0m     hctx \u001B[38;5;241m=\u001B[39m drvapi\u001B[38;5;241m.\u001B[39mcu_context(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 487\u001B[0m     \u001B[43mdriver\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuCtxGetCurrent\u001B[49m(byref(hctx))\n\u001B[0;32m    488\u001B[0m     hctx \u001B[38;5;241m=\u001B[39m hctx \u001B[38;5;28;01mif\u001B[39;00m hctx\u001B[38;5;241m.\u001B[39mvalue \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    490\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m hctx \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:287\u001B[0m, in \u001B[0;36mDriver.__getattr__\u001B[1;34m(self, fname)\u001B[0m\n\u001B[0;32m    284\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m    286\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialization_error \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 287\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m CudaSupportError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mError at driver init: \u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m:\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m\n\u001B[0;32m    288\u001B[0m                            \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39minitialization_error)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m USE_NV_BINDING:\n\u001B[0;32m    291\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_cuda_python_wrap_fn(fname)\n",
      "\u001B[1;31mCudaSupportError\u001B[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# cuda.detect()\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def another_kernel(a):\n",
    "    \"\"\"Commands to get thread positions\"\"\"\n",
    "    # Get the thread position in a thread block\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    tz = cuda.threadIdx.z\n",
    "    print(tx, ty, tz)\n",
    "\n",
    "    # Get the id of the thread block\n",
    "    block_x = cuda.blockIdx.x\n",
    "    block_y = cuda.blockIdx.y\n",
    "    block_z = cuda.blockIdx.z\n",
    "\n",
    "    # Number of threads per block\n",
    "    dim_x = cuda.blockDim.x\n",
    "    dim_y = cuda.blockDim.y\n",
    "    dim_z = cuda.blockDim.z\n",
    "\n",
    "    # Global thread position\n",
    "    pos_x = tx + block_x * dim_x\n",
    "    pos_y = ty + block_y * dim_y\n",
    "    pos_z = tz + block_z * dim_z\n",
    "\n",
    "    # We can also use the grid function to get\n",
    "    # the global position\n",
    "    (pos_x, pos_y, pos_z) = cuda.grid(3)\n",
    "    print(pos_x, pos_y, pos_z)\n",
    "    a[:]=(tx,ty,tz)\n",
    "    # For a 1-or 2-d grid use grid(1) or grid(2)\n",
    "    # to return a scalar or a two tuple.\n",
    "\n",
    "\n",
    "threadsperblock = (16, 16, 1)  # Should be a multiple of 32 if possible.\n",
    "blockspergrid = (8, 8, 8)  # Blocks per grid\n",
    "A=np.zeros(3)\n",
    "\n",
    "another_kernel[blockspergrid, threadsperblock](A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "def discretise_poisson(N):\n",
    "    \"\"\"Generate the matrix and rhs associated with the discrete Poisson operator.\"\"\"\n",
    "\n",
    "    nelements = 5 * N**2 - 16 * N + 16\n",
    "\n",
    "    row_ind = np.empty(nelements, dtype=np.float64)\n",
    "    col_ind = np.empty(nelements, dtype=np.float64)\n",
    "    data = np.empty(nelements, dtype=np.float64)\n",
    "\n",
    "    f = np.empty(N * N, dtype=np.float64)\n",
    "\n",
    "    count = 0\n",
    "    for j in range(N):\n",
    "        for i in range(N):\n",
    "            if i == 0 or i == N - 1 or j == 0 or j == N - 1:\n",
    "                row_ind[count] = col_ind[count] = j * N + i\n",
    "                data[count] =  1\n",
    "                f[j * N + i] = 0\n",
    "                count += 1\n",
    "\n",
    "            else:\n",
    "                row_ind[count : count + 5] = j * N + i\n",
    "                col_ind[count] = j * N + i\n",
    "                col_ind[count + 1] = j * N + i + 1\n",
    "                col_ind[count + 2] = j * N + i - 1\n",
    "                col_ind[count + 3] = (j + 1) * N + i\n",
    "                col_ind[count + 4] = (j - 1) * N + i\n",
    "\n",
    "                data[count] = 4 * (N - 1)**2\n",
    "                data[count + 1 : count + 5] = - (N - 1)**2\n",
    "                f[j * N + i] = 1\n",
    "\n",
    "                count += 5\n",
    "    print(row_ind,'\\n')\n",
    "    print(col_ind,'\\n')\n",
    "    print(data)\n",
    "    return coo_matrix((data, (row_ind, col_ind)), shape=(N**2, N**2)).tocsr(), f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  2.  3.  4.  5.  5.  5.  5.  5.  6.  6.  6.  6.  6.  7.  8.  9.\n",
      "  9.  9.  9.  9. 10. 10. 10. 10. 10. 11. 12. 13. 14. 15.] \n",
      "\n",
      "[ 0.  1.  2.  3.  4.  5.  6.  4.  9.  1.  6.  7.  5. 10.  2.  7.  8.  9.\n",
      " 10.  8. 13.  5. 10. 11.  9. 14.  6. 11. 12. 13. 14. 15.] \n",
      "\n",
      "[ 1.  1.  1.  1.  1. 36. -9. -9. -9. -9. 36. -9. -9. -9. -9.  1.  1. 36.\n",
      " -9. -9. -9. -9. 36. -9. -9. -9. -9.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0. -9.  0.  0. -9. 36. -9.  0.  0. -9.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0. -9.  0.  0. -9. 36. -9.  0.  0. -9.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0. -9.  0.  0. -9. 36. -9.  0.  0. -9.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0. -9.  0.  0. -9. 36. -9.  0.  0. -9.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]] (16, 16)\n",
      "[0. 0. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "A,f=discretise_poisson(4)\n",
    "print(A.toarray(),A.shape)\n",
    "print(f)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
