{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 44>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m blockspergrid \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m, \u001b[38;5;241m8\u001b[39m)  \u001b[38;5;66;03m# Blocks per grid\u001b[39;00m\n\u001b[0;32m     42\u001b[0m A\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m---> 44\u001b[0m \u001b[43manother_kernel\u001b[49m\u001b[43m[\u001b[49m\u001b[43mblockspergrid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mthreadsperblock\u001b[49m\u001b[43m]\u001b[49m(A)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:862\u001b[0m, in \u001b[0;36mDispatcher.__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    860\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]:\n\u001b[0;32m    861\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmust specify at least the griddim and blockdim\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 862\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconfigure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:857\u001b[0m, in \u001b[0;36mDispatcher.configure\u001b[1;34m(self, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconfigure\u001b[39m(\u001b[38;5;28mself\u001b[39m, griddim, blockdim, stream\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, sharedmem\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m):\n\u001b[0;32m    856\u001b[0m     griddim, blockdim \u001b[38;5;241m=\u001b[39m normalize_kernel_dimensions(griddim, blockdim)\n\u001b[1;32m--> 857\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_KernelConfiguration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgriddim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mblockdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msharedmem\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\compiler.py:718\u001b[0m, in \u001b[0;36m_KernelConfiguration.__init__\u001b[1;34m(self, dispatcher, griddim, blockdim, stream, sharedmem)\u001b[0m\n\u001b[0;32m    715\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msharedmem \u001b[38;5;241m=\u001b[39m sharedmem\n\u001b[0;32m    717\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39mCUDA_LOW_OCCUPANCY_WARNINGS:\n\u001b[1;32m--> 718\u001b[0m     ctx \u001b[38;5;241m=\u001b[39m \u001b[43mget_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    719\u001b[0m     smcount \u001b[38;5;241m=\u001b[39m ctx\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mMULTIPROCESSOR_COUNT\n\u001b[0;32m    720\u001b[0m     grid_size \u001b[38;5;241m=\u001b[39m griddim[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m griddim[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m griddim[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:220\u001b[0m, in \u001b[0;36mget_context\u001b[1;34m(devnum)\u001b[0m\n\u001b[0;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_context\u001b[39m(devnum\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;124;03m\"\"\"Get the current device or use a device by device number, and\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;124;03m    return the CUDA context.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_runtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_or_create_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:138\u001b[0m, in \u001b[0;36m_Runtime.get_or_create_context\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    136\u001b[0m attached_ctx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_attached_context()\n\u001b[0;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attached_ctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 138\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_or_create_context_uncached\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevnum\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m attached_ctx\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\devices.py:153\u001b[0m, in \u001b[0;36m_Runtime._get_or_create_context_uncached\u001b[1;34m(self, devnum)\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[38;5;124;03m\"\"\"See also ``get_or_create_context(devnum)``.\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;124;03mThis version does not read the cache.\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m    151\u001b[0m     \u001b[38;5;66;03m# Try to get the active context in the CUDA stack or\u001b[39;00m\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# activate GPU-0 with the primary context\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m driver\u001b[38;5;241m.\u001b[39mget_active_context() \u001b[38;5;28;01mas\u001b[39;00m ac:\n\u001b[0;32m    154\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ac:\n\u001b[0;32m    155\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activate_context_for(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:487\u001b[0m, in \u001b[0;36m_ActiveContext.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    485\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    486\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m drvapi\u001b[38;5;241m.\u001b[39mcu_context(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m--> 487\u001b[0m     \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuCtxGetCurrent\u001b[49m(byref(hctx))\n\u001b[0;32m    488\u001b[0m     hctx \u001b[38;5;241m=\u001b[39m hctx \u001b[38;5;28;01mif\u001b[39;00m hctx\u001b[38;5;241m.\u001b[39mvalue \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    490\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m hctx \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Program Files\\Anaconda3\\lib\\site-packages\\numba\\cuda\\cudadrv\\driver.py:287\u001b[0m, in \u001b[0;36mDriver.__getattr__\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 287\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CudaSupportError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError at driver init: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[0;32m    288\u001b[0m                            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitialization_error)\n\u001b[0;32m    290\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m USE_NV_BINDING:\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cuda_python_wrap_fn(fname)\n",
      "\u001b[1;31mCudaSupportError\u001b[0m: Error at driver init: \n\nCUDA driver library cannot be found.\nIf you are sure that a CUDA driver is installed,\ntry setting environment variable NUMBA_CUDA_DRIVER\nwith the file path of the CUDA driver shared library.\n:"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import cuda\n",
    "\n",
    "# cuda.detect()\n",
    "\n",
    "\n",
    "@cuda.jit\n",
    "def another_kernel(a):\n",
    "    \"\"\"Commands to get thread positions\"\"\"\n",
    "    # Get the thread position in a thread block\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.threadIdx.y\n",
    "    tz = cuda.threadIdx.z\n",
    "    print(tx, ty, tz)\n",
    "\n",
    "    # Get the id of the thread block\n",
    "    block_x = cuda.blockIdx.x\n",
    "    block_y = cuda.blockIdx.y\n",
    "    block_z = cuda.blockIdx.z\n",
    "\n",
    "    # Number of threads per block\n",
    "    dim_x = cuda.blockDim.x\n",
    "    dim_y = cuda.blockDim.y\n",
    "    dim_z = cuda.blockDim.z\n",
    "\n",
    "    # Global thread position\n",
    "    pos_x = tx + block_x * dim_x\n",
    "    pos_y = ty + block_y * dim_y\n",
    "    pos_z = tz + block_z * dim_z\n",
    "\n",
    "    # We can also use the grid function to get\n",
    "    # the global position\n",
    "    (pos_x, pos_y, pos_z) = cuda.grid(3)\n",
    "    print(pos_x, pos_y, pos_z)\n",
    "    a[:]=(tx,ty,tz)\n",
    "    # For a 1-or 2-d grid use grid(1) or grid(2)\n",
    "    # to return a scalar or a two tuple.\n",
    "\n",
    "\n",
    "threadsperblock = (16, 16, 1)  # Should be a multiple of 32 if possible.\n",
    "blockspergrid = (8, 8, 8)  # Blocks per grid\n",
    "A=np.zeros(3)\n",
    "\n",
    "another_kernel[blockspergrid, threadsperblock](A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
